{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importar\n",
    "import os\n",
    "from datetime import datetime\n",
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import pandas as pd\n",
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from collections import OrderedDict\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "import getpass\n",
    "import pyshorteners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def realizar_login(url, login1, password1, orgao1):\n",
    "    \"\"\"\n",
    "    Função para realizar login no sistema SEI.\n",
    "\n",
    "    Args:\n",
    "        url (str): URL do sistema SEI.\n",
    "        login1 (str): Nome de usuário para login.\n",
    "        password1 (str): Senha para login.\n",
    "        orgao1 (str): Nome do órgão para acesso.\n",
    "\n",
    "    Returns:\n",
    "        webdriver: Instância do WebDriver com o usuário autenticado.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Inicializa o navegador\n",
    "        driver = webdriver.Chrome()\n",
    "        driver.implicitly_wait(0.5)\n",
    "        driver.get(url)\n",
    "\n",
    "        # Localiza os elementos de login\n",
    "        login = driver.find_element(By.XPATH, '//*[@id=\"txtUsuario\"]')\n",
    "        password = driver.find_element(By.XPATH, '//*[@id=\"pwdSenha\"]')\n",
    "        orgao = driver.find_element(By.XPATH, '//*[@id=\"selOrgao\"]')\n",
    "        submit_button = driver.find_element(By.XPATH, '//*[@id=\"Acessar\"]')\n",
    "\n",
    "        # Preenche as credenciais\n",
    "        login.send_keys(login1)\n",
    "        password.send_keys(password1)\n",
    "        orgao.send_keys(orgao1)\n",
    "\n",
    "        # Realiza o login\n",
    "        submit_button.click()\n",
    "        time.sleep(3)  # Aguarda carregamento da página após o login\n",
    "\n",
    "        print(\"Login realizado com sucesso!\")\n",
    "        return driver\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao realizar o login: {e}\")\n",
    "        return None\n",
    "\n",
    "# Função principal para busca\n",
    "def buscar_arquivos(driver):\n",
    "    \"\"\"\n",
    "    Realiza a busca de arquivos no sistema SEI após login.\n",
    "\n",
    "    Args:\n",
    "        driver (webdriver): Instância do WebDriver autenticada.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Acessa a área de busca\n",
    "        searching = driver.find_element(By.XPATH, '//*[@id=\"infraMenu\"]/li[14]/a/span')\n",
    "        searching.click()\n",
    "        time.sleep(1)\n",
    "\n",
    "        # Restringe busca ao órgão específico\n",
    "        sel_orgao = driver.find_element(By.XPATH, '//*[@id=\"divSinRestringirOrgao\"]/div')\n",
    "        sel_orgao.click()\n",
    "        time.sleep(1)\n",
    "\n",
    "        # Especifica os termos de pesquisa\n",
    "        espec_pesq = driver.find_element(By.XPATH, '//*[@id=\"txtDescricaoPesquisa\"]')\n",
    "        espec_pesq.send_keys('\"Projeto Lei\" ou \"PL\" ou \"RIC\" ou \"Projeto de Lei\" ou \"Requisição de Informação\" ou \"PLOA\" ou \"PLN\" ou \"PLC\"')\n",
    "        \n",
    "        #colocar como tramitação dentro do orgão\n",
    "        chktram = driver.find_element(By.XPATH, '//*[@id=\"divSinTramitacao\"]/div')\n",
    "        chktram.click()\n",
    "        time.sleep(0.2)\n",
    "\n",
    "        # Realiza a pesquisa\n",
    "        b_pesq = driver.find_element(By.XPATH, '//*[@id=\"sbmPesquisar\"]')\n",
    "        b_pesq.click()\n",
    "        time.sleep(3)\n",
    "\n",
    "        print(\"Busca realizada com sucesso.\\nRestringindo em PL e dentro do MGI.\\n\\nOs Externo entram como MGI.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Erro durante a busca: {e}\")\n",
    "\n",
    "# Exemplo de uso\n",
    "url = 'https://sei.economia.gov.br/'\n",
    "login1 = '  '\n",
    "password1 = \" \"\n",
    "orgao1 = \"MGI\"\n",
    "\n",
    "# Realiza login\n",
    "driver = realizar_login(url, login1, password1, orgao1)\n",
    "\n",
    "# Se o login foi bem-sucedido, realiza a busca\n",
    "if driver:\n",
    "    buscar_arquivos(driver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extrair_dados(driver):     \n",
    "    \"\"\"\n",
    "    Função para realizar web scraping no SEI e retornar os dados em um DataFrame.\n",
    "\n",
    "    Args:\n",
    "        driver (webdriver): Instância do Selenium WebDriver.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame contendo os dados extraídos.\n",
    "    \"\"\"\n",
    "    def remove_items(lista, item): \n",
    "        \"\"\"Remove todos os itens iguais a `item` de uma lista.\"\"\"\n",
    "        return [i for i in lista if i != item]\n",
    "\n",
    "    # Extraindo os elementos da pesquisa\n",
    "    tree_elements = driver.find_elements(\"xpath\", '//*[@class=\"pesquisaTituloEsquerda\"]/a')\n",
    "    list_tree = [element.text for element in tree_elements]\n",
    "    trees = remove_items(list_tree, '')  # Remover elementos vazios\n",
    "\n",
    "    abts = driver.find_elements(\"xpath\", '//*[@class=\"pesquisaSnippet\"]')\n",
    "    list_abts = [element.text for element in abts]\n",
    "\n",
    "    unidades = driver.find_elements(\"xpath\", '//*[@class=\"pesquisaMetatag\"]')\n",
    "    list_uni = [element.text.split(':') for element in unidades]\n",
    "    info = [sublist_uni[1] for sublist_uni in list_uni if len(sublist_uni) > 1]  # Removendo listas vazias\n",
    "\n",
    "    rows = driver.find_elements(\"xpath\", '//*[@id=\"conteudo\"]/table/tbody/tr')\n",
    "    links = []\n",
    "    for i in range(1, len(rows), 3):\n",
    "        try:\n",
    "            a = driver.find_element(\"xpath\", f'//*[@id=\"conteudo\"]/table/tbody/tr[{i}]/td[1]/a[1]')\n",
    "            time.sleep(0.5)\n",
    "            link = a.get_attribute('href')\n",
    "            time.sleep(0.5)\n",
    "            links.append(link)\n",
    "        except Exception as e:\n",
    "            print(f\"Erro ao processar a linha {i}: {e}\")\n",
    "\n",
    "    shortener = pyshorteners.Shortener()\n",
    "    links_curtos = []\n",
    "    for link in links:\n",
    "        try:\n",
    "            link_curto = shortener.tinyurl.short(link)\n",
    "            links_curtos.append(link_curto)\n",
    "            time.sleep(3)\n",
    "        except Exception as e:\n",
    "            print(f\"Erro ao encurtar o link {link}: {e}\")\n",
    "\n",
    "    dados = {\n",
    "        \"Número do Processo\": trees[::2],\n",
    "        \"Documento\": trees[1::2],\n",
    "        \"Resumo\": list_abts,\n",
    "        \"Unidade\": info[::3],\n",
    "        \"Usuário\": info[1::3],\n",
    "        \"Data de Inclusão\": info[2::3],\n",
    "        \"Links\": links_curtos\n",
    "    }\n",
    "\n",
    "    df = pd.DataFrame(dados)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def navegar_paginas(driver):\n",
    "    \"\"\"\n",
    "    Loop para navegar por todas as páginas até que não haja mais um botão 'Próxima'.\n",
    "    Retorna um DataFrame consolidado com os dados de todas as páginas.\n",
    "    \"\"\"\n",
    "    dados_consolidados = pd.DataFrame()  # DataFrame vazio para acumular os dados\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            # Extrair os dados da página atual e adicionar ao DataFrame consolidado\n",
    "            df_pagina = extrair_dados(driver)\n",
    "            dados_consolidados = pd.concat([dados_consolidados, df_pagina], ignore_index=True)\n",
    "\n",
    "            # Procurar o botão \"Próxima\"\n",
    "            next_page = driver.find_element(\"xpath\", '//*[@id=\"conteudo\"]/div[2]/div[3]/a')\n",
    "\n",
    "            # Verificar se o botão \"Próxima\" tem o atributo 'href'\n",
    "            proxima_href = next_page.get_attribute('href')\n",
    "            time.sleep(3)\n",
    "            if not proxima_href:\n",
    "                print(\"Não há mais páginas. Encerrando navegação.\")\n",
    "                break  # Sai do loop se não houver link para a próxima página\n",
    "\n",
    "            # Clicar no botão \"Próxima\"\n",
    "            next_page.click()\n",
    "            time.sleep(10)  # Aguarda o carregamento da próxima página\n",
    "\n",
    "        except NoSuchElementException:\n",
    "            print(\"Botão 'Próxima' não encontrado. Encerrando navegação.\")\n",
    "            break  # Sai do loop se o botão \"Próxima\" não existir\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Erro inesperado: {e}\")\n",
    "            break  # Sai do loop em caso de erro inesperado\n",
    "\n",
    "    # Fechar o navegador após o término\n",
    "    # driver.close()\n",
    "    # driver.quit()\n",
    "\n",
    "    return dados_consolidados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados = navegar_paginas(driver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bootcamp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

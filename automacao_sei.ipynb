{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '.venv (Python 3.12.10)' requires the ipykernel package.\n",
      "\u001b[1;31mInstall 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'd:/github/.venv/Scripts/python.exe -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "#importar\n",
    "import os\n",
    "from datetime import datetime\n",
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import pandas as pd\n",
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from collections import OrderedDict\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "import getpass\n",
    "import pyshorteners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '.venv (Python 3.12.10)' requires the ipykernel package.\n",
      "\u001b[1;31mInstall 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'd:/github/.venv/Scripts/python.exe -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "def realizar_login(url, login1, password1, orgao1):\n",
    "    \"\"\"\n",
    "    Função para realizar login no sistema SEI.\n",
    "\n",
    "    Args:\n",
    "        url (str): URL do sistema SEI.\n",
    "        login1 (str): Nome de usuário para login.\n",
    "        password1 (str): Senha para login.\n",
    "        orgao1 (str): Nome do órgão para acesso.\n",
    "\n",
    "    Returns:\n",
    "        webdriver: Instância do WebDriver com o usuário autenticado.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Inicializa o navegador\n",
    "        driver = webdriver.Chrome()\n",
    "        driver.implicitly_wait(0.5)\n",
    "        driver.get(url)\n",
    "\n",
    "        # Localiza os elementos de login\n",
    "        login = driver.find_element(By.XPATH, '//*[@id=\"txtUsuario\"]')\n",
    "        password = driver.find_element(By.XPATH, '//*[@id=\"pwdSenha\"]')\n",
    "        orgao = driver.find_element(By.XPATH, '//*[@id=\"selOrgao\"]')\n",
    "        submit_button = driver.find_element(By.XPATH, '//*[@id=\"Acessar\"]')\n",
    "\n",
    "        # Preenche as credenciais\n",
    "        login.send_keys(login1)\n",
    "        password.send_keys(password1)\n",
    "        orgao.send_keys(orgao1)\n",
    "\n",
    "        # Realiza o login\n",
    "        submit_button.click()\n",
    "        time.sleep(3)  # Aguarda carregamento da página após o login\n",
    "\n",
    "        print(\"Login realizado com sucesso!\")\n",
    "        return driver\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao realizar o login: {e}\")\n",
    "        return None\n",
    "\n",
    "# Função principal para busca\n",
    "def buscar_arquivos(driver):\n",
    "    \"\"\"\n",
    "    Realiza a busca de arquivos no sistema SEI após login.\n",
    "\n",
    "    Args:\n",
    "        driver (webdriver): Instância do WebDriver autenticada.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Acessa a área de busca\n",
    "        searching = driver.find_element(By.XPATH, '//*[@id=\"infraMenu\"]/li[14]/a/span')\n",
    "        searching.click()\n",
    "        time.sleep(1)\n",
    "\n",
    "        # Restringe busca ao órgão específico\n",
    "        sel_orgao = driver.find_element(By.XPATH, '//*[@id=\"divSinRestringirOrgao\"]/div')\n",
    "        sel_orgao.click()\n",
    "        time.sleep(1)\n",
    "\n",
    "        # Especifica os termos de pesquisa\n",
    "        espec_pesq = driver.find_element(By.XPATH, '//*[@id=\"txtDescricaoPesquisa\"]')\n",
    "        espec_pesq.send_keys('MPS e SEGES não \"Serviço de Informações ao Cidadão\" não \"Capacitação\" não \"Avaliação de Reação\" não \"Termo de Responsabilidade - Controle de Acesso\" não \"Solicitação de Cessão\" não \"TERMO ANUÊNCIA\"')\n",
    "        \n",
    "        #colocar como tramitação dentro do orgão\n",
    "        chktram = driver.find_element(By.XPATH, '//*[@id=\"divSinTramitacao\"]/div')\n",
    "        chktram.click()\n",
    "        time.sleep(0.2)\n",
    "\n",
    "        # Realiza a pesquisa\n",
    "        b_pesq = driver.find_element(By.XPATH, '//*[@id=\"sbmPesquisar\"]')\n",
    "        b_pesq.click()\n",
    "        time.sleep(3)\n",
    "\n",
    "        print(\"Busca realizada com sucesso.\\nRestringindo em PL e dentro do MGI.\\n\\nOs Externo entram como MGI.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Erro durante a busca: {e}\")\n",
    "\n",
    "# Exemplo de uso\n",
    "url = 'hhttps://colaboragov.sei.gov.br/sip/modulos/MF/login_especial/login_especial.php?sigla_orgao_sistema=MGI&sigla_sistema=SEI'\n",
    "login1 = ''\n",
    "password1 = \"\"\n",
    "orgao1 = \"MGI\"\n",
    "\n",
    "# Realiza login\n",
    "driver = realizar_login(url, login1, password1, orgao1)\n",
    "\n",
    "# Se o login foi bem-sucedido, realiza a busca\n",
    "if driver:\n",
    "    buscar_arquivos(driver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extrair_dados(driver):     \n",
    "    \"\"\"\n",
    "    Função para realizar web scraping no SEI e retornar os dados em um DataFrame.\n",
    "\n",
    "    Args:\n",
    "        driver (webdriver): Instância do Selenium WebDriver.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame contendo os dados extraídos.\n",
    "    \"\"\"\n",
    "    def remove_items(lista, item): \n",
    "        \"\"\"Remove todos os itens iguais a `item` de uma lista.\"\"\"\n",
    "        return [i for i in lista if i != item]\n",
    "\n",
    "    # Extraindo os elementos da pesquisa\n",
    "    tree_elements = driver.find_elements(\"xpath\", '//*[@class=\"pesquisaTituloEsquerda\"]/a')\n",
    "    list_tree = [element.text for element in tree_elements]\n",
    "    trees = remove_items(list_tree, '')  # Remover elementos vazios\n",
    "\n",
    "    abts = driver.find_elements(\"xpath\", '//*[@class=\"pesquisaSnippet\"]')\n",
    "    list_abts = [element.text for element in abts]\n",
    "\n",
    "    unidades = driver.find_elements(\"xpath\", '//*[@class=\"pesquisaMetatag\"]')\n",
    "    list_uni = [element.text.split(':') for element in unidades]\n",
    "    info = [sublist_uni[1] for sublist_uni in list_uni if len(sublist_uni) > 1]  # Removendo listas vazias\n",
    "\n",
    "    rows = driver.find_elements(\"xpath\", '//*[@id=\"conteudo\"]/table/tbody/tr')\n",
    "    links = []\n",
    "    for i in range(1, len(rows), 3):\n",
    "        try:\n",
    "            a = driver.find_element(\"xpath\", f'//*[@id=\"conteudo\"]/table/tbody/tr[{i}]/td[1]/a[1]')\n",
    "            time.sleep(0.5)\n",
    "            link = a.get_attribute('href')\n",
    "            time.sleep(0.5)\n",
    "            links.append(link)\n",
    "        except Exception as e:\n",
    "            print(f\"Erro ao processar a linha {i}: {e}\")\n",
    "\n",
    "    shortener = pyshorteners.Shortener()\n",
    "    links_curtos = []\n",
    "    for link in links:\n",
    "        try:\n",
    "            link_curto = shortener.tinyurl.short(link)\n",
    "            links_curtos.append(link_curto)\n",
    "            time.sleep(3)\n",
    "        except Exception as e:\n",
    "            print(f\"Erro ao encurtar o link {link}: {e}\")\n",
    "\n",
    "    dados = {\n",
    "        \"Número do Processo\": trees[::2],\n",
    "        \"Documento\": trees[1::2],\n",
    "        \"Resumo\": list_abts,\n",
    "        \"Unidade\": info[::3],\n",
    "        \"Usuário\": info[1::3],\n",
    "        \"Data de Inclusão\": info[2::3],\n",
    "        \"Links\": links_curtos\n",
    "    }\n",
    "\n",
    "    df = pd.DataFrame(dados)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import logging\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "\n",
    "# --- Configuração de Logging ---\n",
    "# Usar logging é melhor do que 'print' para rastrear o que o script está fazendo,\n",
    "# especialmente para erros.\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO, \n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler(\"automacao_sei.log\"),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def criar_pastas(pasta_documentos, pasta_listas):\n",
    "    \"\"\"Garante que os diretórios para salvar os arquivos existam.\"\"\"\n",
    "    os.makedirs(pasta_documentos, exist_ok=True)\n",
    "    os.makedirs(pasta_listas, exist_ok=True)\n",
    "    logging.info(f\"Pasta de documentos '{pasta_documentos}' e de listas '{pasta_listas}' prontas.\")\n",
    "\n",
    "\n",
    "def salvar_documentos_da_pagina(driver, pasta_documentos, caminho_lista_arquivos):\n",
    "    \"\"\"\n",
    "    Localiza todos os documentos na página de resultados de busca atual do SEI,\n",
    "    salva cada um como um arquivo HTML e registra os nomes em um arquivo de texto.\n",
    "\n",
    "    Esta função substitui a sua função 'get_files' original.\n",
    "\n",
    "    Args:\n",
    "        driver (webdriver): A instância do WebDriver do Selenium.\n",
    "        pasta_documentos (str): O caminho da pasta onde os arquivos HTML serão salvos.\n",
    "        caminho_lista_arquivos (str): O caminho completo do arquivo .txt para registrar os nomes dos arquivos.\n",
    "    \"\"\"\n",
    "    janela_original = driver.current_window_handle\n",
    "    \n",
    "    try:\n",
    "        # Em vez de pegar todo o texto, encontramos cada 'tabela' que representa um resultado.\n",
    "        # Isto é mais robusto que usar um índice no XPath.\n",
    "        tabelas_de_resultado = driver.find_elements(By.XPATH, \"//div[@id='conteudo']/table\")\n",
    "        \n",
    "        if not tabelas_de_resultado:\n",
    "            logging.info(\"Nenhum documento encontrado na página atual.\")\n",
    "            return\n",
    "\n",
    "        logging.info(f\"Encontrados {len(tabelas_de_resultado)} documentos na página.\")\n",
    "\n",
    "        for tabela in tabelas_de_resultado:\n",
    "            nome_doc = \"nome_nao_encontrado\"\n",
    "            try:\n",
    "                # 1. Encontrar o nome do documento e o link para o processo\n",
    "                # O seletor busca pelo link que tem o tooltip, que geralmente contém o nome.\n",
    "                elemento_nome = tabela.find_element(By.XPATH, \".//a[contains(@onmouseover, 'return infraTooltipMostrar')]\")\n",
    "                nome_doc = elemento_nome.text.strip()\n",
    "\n",
    "                # Limpa o nome do documento para criar um nome de arquivo válido\n",
    "                nome_arquivo_seguro = \"\".join([c for c in nome_doc if c.isalnum() or c in (' ', '-')]).rstrip()\n",
    "                \n",
    "                # 2. Encontrar o link para abrir a página do documento\n",
    "                # O XPath original usava a[2], então mantemos uma lógica parecida, mas relativa à tabela.\n",
    "                elemento_link_doc = tabela.find_element(By.XPATH, \".//tr[1]/td[1]/a[2]\")\n",
    "                link_doc = elemento_link_doc.get_attribute('href')\n",
    "\n",
    "                if not link_doc:\n",
    "                    logging.warning(f\"Não foi possível encontrar o link para o documento: {nome_doc}\")\n",
    "                    continue\n",
    "\n",
    "                # 3. Salvar o nome do arquivo na lista de texto\n",
    "                with open(caminho_lista_arquivos, 'a', encoding='utf-8') as f:\n",
    "                    f.write(nome_arquivo_seguro + '\\n')\n",
    "\n",
    "                # 4. Abrir o documento em uma nova aba, salvar o HTML e fechar\n",
    "                driver.switch_to.new_window('tab')\n",
    "                driver.get(link_doc)\n",
    "                \n",
    "                # Use UTF-8, é um padrão mais moderno e evita problemas com caracteres especiais.\n",
    "                caminho_html = os.path.join(pasta_documentos, f\"documento_{nome_arquivo_seguro}.html\")\n",
    "                with open(caminho_html, 'w', encoding='utf-8') as f:\n",
    "                    f.write(driver.page_source)\n",
    "                \n",
    "                logging.info(f\"Documento salvo: {caminho_html}\")\n",
    "                \n",
    "                driver.close()\n",
    "                driver.switch_to.window(janela_original)\n",
    "                time.sleep(1) # Pequena pausa para estabilidade\n",
    "\n",
    "            except NoSuchElementException:\n",
    "                logging.error(f\"Não foi possível encontrar o nome ou o link para um documento na tabela. Pulando.\")\n",
    "                # Garante que, se uma nova aba foi aberta, ela seja fechada antes de continuar.\n",
    "                if len(driver.window_handles) > 1:\n",
    "                    driver.close()\n",
    "                    driver.switch_to.window(janela_original)\n",
    "                continue\n",
    "            except Exception as e:\n",
    "                logging.error(f\"Ocorreu um erro ao processar o documento '{nome_doc}': {e}\")\n",
    "                if len(driver.window_handles) > 1:\n",
    "                    driver.close()\n",
    "                    driver.switch_to.window(janela_original)\n",
    "                continue\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Ocorreu um erro geral ao tentar salvar os documentos da página: {e}\")\n",
    "\n",
    "def navegar_e_salvar_documentos(driver, pasta_documentos, pasta_listas):\n",
    "    \"\"\"\n",
    "    Navega pelas páginas de resultados, chamando a função para salvar \n",
    "    os documentos de cada página.\n",
    "\n",
    "    Esta função substitui a sua 'navegar_paginas'.\n",
    "    \"\"\"\n",
    "    from datetime import datetime\n",
    "    \n",
    "    today_date = datetime.now().strftime('%Y-%m-%d')\n",
    "    caminho_lista_arquivos = os.path.join(pasta_listas, f'lista_arquivos_{today_date}.txt')\n",
    "\n",
    "    pagina_atual = 1\n",
    "    while True:\n",
    "        logging.info(f\"--- Processando página {pagina_atual} ---\")\n",
    "        \n",
    "        # Chama a função para salvar os documentos da página atual\n",
    "        salvar_documentos_da_pagina(driver, pasta_documentos, caminho_lista_arquivos)\n",
    "\n",
    "        try:\n",
    "            # Procura o botão \"Próxima\"\n",
    "            botao_proxima = driver.find_element(By.XPATH, \"//a[text()='Próxima']\")\n",
    "            \n",
    "            # Clica no botão para ir para a próxima página\n",
    "            logging.info(\"Indo para a próxima página...\")\n",
    "            botao_proxima.click()\n",
    "            time.sleep(5)  # Aguarda o carregamento da próxima página\n",
    "            pagina_atual += 1\n",
    "\n",
    "        except NoSuchElementException:\n",
    "            logging.info(\"Botão 'Próxima' não encontrado. Fim da navegação.\")\n",
    "            break  # Sai do loop se o botão \"Próxima\" não existir\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Erro ao tentar navegar para a próxima página: {e}\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_words_after_lei(url):\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        text = soup.get_text()\n",
    "        words = text.split()\n",
    "        if \"Lei\" in words:\n",
    "            lei_index = words.index(\"Lei\")\n",
    "            return ' '.join(words[lei_index + 1:lei_index + 3])\n",
    "        else:\n",
    "            return None\n",
    "    except requests.RequestException as e:\n",
    "        print(f\"Error fetching URL {url}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_files():\n",
    "    \n",
    "        original_window = driver.current_window_handle \n",
    "        page_docs_search = driver.find_element(\"xpath\", '//*[@id=\"conteudo\"]')\n",
    "        page_docs = page_docs_search.text.split('Atividade Fim: ')[1:]\n",
    "        \n",
    "        file_name = []\n",
    "        for i in range(len(page_docs)):\n",
    "            a = page_docs[i].split('(REMA - Empréstimo de Materiais ou Ex. Geológicos) ')[1].split('\\n1')[0]\n",
    "            file_name.append(a)\n",
    "        with open(os.path.join(\".\", nomes_arquivos, f'{today_date}.txt'), 'a') as file:\n",
    "            file.write(a +'\\n')\n",
    "        # file.close()\n",
    "\n",
    "        links = []\n",
    "        for i in range(1, len(page_docs)+1):\n",
    "            a = driver.find_element(\"xpath\", '//*[@id=\"conteudo\"]/table[%s]/tbody/tr[1]/td[1]/a[2]' %i)\n",
    "            link = a.get_attribute('href')\n",
    "            links.append(link)\n",
    "        \n",
    "        index = -1\n",
    "        for i in links:\n",
    "            index +=1\n",
    "            name = file_name[index]\n",
    "            driver.switch_to.new_window('tab')\n",
    "            driver.get(i)\n",
    "            with open(os.path.join(\".\", pasta, f\"documento_{name}.html\"), 'w', encoding='iso-8859-1') as file:\n",
    "                file.write(driver.page_source)        \n",
    "            driver.close()\n",
    "            driver.switch_to.window(original_window)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def navegar_paginas(driver):\n",
    "    \"\"\"\n",
    "    Loop para navegar por todas as páginas até que não haja mais um botão 'Próxima'.\n",
    "    Retorna um DataFrame consolidado com os dados de todas as páginas.\n",
    "    \"\"\"\n",
    "    dados_consolidados = pd.DataFrame()  # DataFrame vazio para acumular os dados\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            # Extrair os dados da página atual e adicionar ao DataFrame consolidado\n",
    "            df_pagina = extrair_dados(driver)\n",
    "            dados_consolidados = pd.concat([dados_consolidados, df_pagina], ignore_index=True)\n",
    "\n",
    "            # Procurar o botão \"Próxima\"\n",
    "            next_page = driver.find_element(\"xpath\", '//*[@id=\"conteudo\"]/div[2]/div[3]/a')\n",
    "\n",
    "            # Verificar se o botão \"Próxima\" tem o atributo 'href'\n",
    "            proxima_href = next_page.get_attribute('href')\n",
    "            time.sleep(3)\n",
    "            if not proxima_href:\n",
    "                print(\"Não há mais páginas. Encerrando navegação.\")\n",
    "                break  # Sai do loop se não houver link para a próxima página\n",
    "\n",
    "            # Clicar no botão \"Próxima\"\n",
    "            next_page.click()\n",
    "            time.sleep(10)  # Aguarda o carregamento da próxima página\n",
    "\n",
    "        except NoSuchElementException:\n",
    "            print(\"Botão 'Próxima' não encontrado. Encerrando navegação.\")\n",
    "            break  # Sai do loop se o botão \"Próxima\" não existir\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Erro inesperado: {e}\")\n",
    "            break  # Sai do loop em caso de erro inesperado\n",
    "\n",
    "    # Fechar o navegador após o término\n",
    "    # driver.close()\n",
    "    # driver.quit()\n",
    "\n",
    "    return dados_consolidados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados = navegar_paginas(driver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
